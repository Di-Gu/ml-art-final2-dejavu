{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manga Colorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black&White manga/comic colorization, based on pix2pix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequests: Python 3, GPU # This notebook was tested in datahub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/ucsd-ml-arts/ml-art-final2-dejavu.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ml-art-final2-dejavu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let Visdom run background, 8097 is the default output port of pix2pix model.\n",
    "get_ipython().system_raw('python3 -m visdom.server -port 8097 >> visdomlog.txt 2>&1 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 8097 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://7b109840.ngrok.io\r\n"
     ]
    }
   ],
   "source": [
    "# Click the link below to access Visdom.\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Download checkpoints from https://drive.google.com/drive/folders/1m5wf2Fb_9XDbyAkBhNHY2E4LMIoEuDrn?usp=sharing \n",
    "Mount checkpoints/ to project directory i.e. ml-art-final2-dejavu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train onepiece pages in grayscale and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using ~150 onepiece pages. More pages will be better.\n",
    "! python train.py --dataroot ./datasets/onepiece/A/ --name color_pix2pix --model colorization --netG unet_512 --load_size 568 --crop_size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate colored pages from B&W testset.\n",
    "! python test.py --dataroot ./datasets/onepiece/A/ --name color_pix2pix --model colorization --netG unet_512 --load_size 512 --crop_size 512 --num_test 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize outputs to appropriate resolution\n",
    "\n",
    "result_dir = \"results/color_pix2pix/test_latest/images/\"\n",
    "\n",
    "img_list = os.listdir(result_dir)\n",
    "num_imgs = len(img_list)\n",
    "for n in range(num_imgs):\n",
    "    name_s = img_list[n]\n",
    "    path_s = os.path.join(result_dir, name_s)\n",
    "    im_s = cv2.imread(path_s, 1)\n",
    "    im_l = cv2.resize(im_s, (520,800), interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(path_s, im_l)\n",
    "    \n",
    "# The result is in html form stored in results/color_pix2pix/test_latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Rick&Morty pages in grayscale and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python train.py --dataroot ./datasets/R2Rs/A/ --name r2r_pix2pix --model colorization --netG unet_512 --load_size 568 --crop_size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python test.py --dataroot ./datasets/R2Rs/A/ --name r2r_pix2pix --model colorization --netG unet_512 --load_size 512 --crop_size 512 --num_test 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"results/r2r_pix2pix/test_latest/images/\"\n",
    "\n",
    "img_list = os.listdir(result_dir)\n",
    "num_imgs = len(img_list)\n",
    "for n in range(num_imgs):\n",
    "    name_s = img_list[n]\n",
    "    path_s = os.path.join(result_dir, name_s)\n",
    "    im_s = cv2.imread(path_s, 1)\n",
    "    im_l = cv2.resize(im_s, (600,900), interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(path_s, im_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Simpsons pages in grayscale and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python train.py --dataroot ./datasets/S2Ss/ --name s2s_pix2pix --model colorization --netG unet_512 --load_size 568 --crop_size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python test.py --dataroot ./datasets/S2Ss/ --name s2s_pix2pix --model colorization --netG unet_512 --load_size 512 --crop_size 512 --num_test 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"results/s2s_pix2pix/test_latest/images/\"\n",
    "\n",
    "img_list = os.listdir(result_dir)\n",
    "num_imgs = len(img_list)\n",
    "for n in range(num_imgs):\n",
    "    name_s = img_list[n]\n",
    "    path_s = os.path.join(result_dir, name_s)\n",
    "    im_s = cv2.imread(path_s, 1)\n",
    "    im_l = cv2.resize(im_s, (600,900), interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(path_s, im_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Simpsons in grayscale and test on Rick&Morty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python train.py --dataroot ./datasets/S2Rs/ --name s2r_pix2pix --model colorization --netG unet_512 --load_size 568 --crop_size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python test.py --dataroot ./datasets/S2Rs/ --name s2r_pix2pix --model colorization --netG unet_512 --load_size 512 --crop_size 512 --num_test 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize outputs to appropriate resolution\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "result_dir = \"results/s2r_pix2pix/test_latest/images/\"\n",
    "\n",
    "img_list = os.listdir(result_dir)\n",
    "num_imgs = len(img_list)\n",
    "for n in range(num_imgs):\n",
    "    name_s = img_list[n]\n",
    "    path_s = os.path.join(result_dir, name_s)\n",
    "    im_s = cv2.imread(path_s, 1)\n",
    "    im_l = cv2.resize(im_s, (600,900), interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(path_s, im_l)\n",
    "    \n",
    "# The result is in html form stored in results/s2r_pix2pix/test_latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Rick&Morty in sketch and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python train.py --dataroot ./datasets/R2Rs_AB/ --name r2r_ab_pix2pix --model pix2pix --direction BtoA --netG unet_512 --load_size 568 --crop_size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python test.py --dataroot ./datasets/R2Rs_AB/ --name r2r_ab_pix2pix --model pix2pix --direction BtoA --netG unet_512 --load_size 512 --crop_size 512 --num_test 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"results/r2r_ab_pix2pix/test_latest/images/\"\n",
    "\n",
    "img_list = os.listdir(result_dir)\n",
    "num_imgs = len(img_list)\n",
    "for n in range(num_imgs):\n",
    "    name_s = img_list[n]\n",
    "    path_s = os.path.join(result_dir, name_s)\n",
    "    im_s = cv2.imread(path_s, 1)\n",
    "    im_l = cv2.resize(im_s, (600,900), interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(path_s, im_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train OnePiece in sketch and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python train.py --dataroot ./datasets/onepiece_AB/ --name o2o_ab_pix2pix --model pix2pix --direction BtoA --netG unet_512 --load_size 568 --crop_size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python test.py --dataroot ./datasets/onepiece_AB/ --name o2o_ab_pix2pix --model pix2pix --direction BtoA --netG unet_512 --load_size 512 --crop_size 512 --num_test 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"results/o2o_ab_pix2pix/test_latest/images/\"\n",
    "\n",
    "img_list = os.listdir(result_dir)\n",
    "num_imgs = len(img_list)\n",
    "for n in range(num_imgs):\n",
    "    name_s = img_list[n]\n",
    "    path_s = os.path.join(result_dir, name_s)\n",
    "    im_s = cv2.imread(path_s, 1)\n",
    "    im_l = cv2.resize(im_s, (600,900), interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(path_s, im_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
